{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be58623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awscli                        1.27.74\n",
      "boto3                         1.26.162\n",
      "botocore                      1.29.162\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"awscli|boto3|botocore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a42e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ad7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role Name: AmazonSageMakerServiceCatalogProductsUseRole\n"
     ]
    }
   ],
   "source": [
    "strSageMakerRoleName = get_execution_role().rsplit('/', 1)[-1]\n",
    "print (f\"SageMaker Execution Role Name: {strSageMakerRoleName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d40da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://preview.documentation.bedrock.aws.dev/Documentation/SDK/bedrock-python-sdk.zip\n",
    "#!unzip bedrock-python-sdk.zip -d bedrock-sdk\n",
    "#!rm -rf bedrock-python-sdk.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6e780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "549c2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    !{sys.executable} -m pip install -U ./bedrock-sdk/botocore-1.29.162-py3-none-any.whl\n",
    "    !{sys.executable} -m pip install -U ./bedrock-sdk/boto3-1.26.162-py3-none-any.whl\n",
    "    !{sys.executable} -m pip install -U ./bedrock-sdk/awscli-1.27.162-py3-none-any.whl\n",
    "    !{sys.executable} -m pip install -U langchain\n",
    "    !rm -rf bedrock-sdk\n",
    "\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c113422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902c7e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain version check: 0.0.249\n",
      "boto3 version check: 1.26.162\n"
     ]
    }
   ],
   "source": [
    "print(f\"langchain version check: {langchain.__version__}\")\n",
    "print(f\"boto3 version check: {boto3.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ac06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_region = \"us-west-2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2098967",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_internal_use = True # 내부 직원 용\n",
    "# is_internal_use = False # 고객 용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db37e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_region = \"us-west-2\" \n",
    "bedrock_region = \"us-west-2\" \n",
    "if bedrock_region == \"us-east-1\":    \n",
    "    bedrock_config = {\n",
    "        \"region_name\":bedrock_region,\n",
    "        \"endpoint_url\":\"https://bedrock.us-east-1.amazonaws.com\"\n",
    "    }\n",
    "elif bedrock_region == \"us-west-2\":  \n",
    "    bedrock_config = {\n",
    "        \"region_name\":bedrock_region,\n",
    "        \"endpoint_url\":\"https://prod.us-west-2.frontend.bedrock.aws.dev\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5019820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_internal_use:\n",
    "    bedrock_client = boto3.client(\n",
    "        service_name='bedrock',\n",
    "        region_name=bedrock_config[\"region_name\"],\n",
    "        endpoint_url=bedrock_config[\"endpoint_url\"]\n",
    "    )\n",
    "else:\n",
    "    bedrock_client = boto3.client(\n",
    "        service_name='bedrock',\n",
    "        region_name=bedrock_config[\"region_name\"]\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f4220a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'bd5253c8-b631-41a3-a89e-95a802d0783a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 17 Aug 2023 23:20:43 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '256',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'bd5253c8-b631-41a3-a89e-95a802d0783a'},\n",
       "  'RetryAttempts': 0},\n",
       " 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-tg1-large',\n",
       "   'modelId': 'amazon.titan-tg1-large'},\n",
       "  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-e1t-medium',\n",
       "   'modelId': 'amazon.titan-e1t-medium'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text = bedrock_client.list_foundation_models()\n",
    "output_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f44f3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prompt\n",
    "prompt_data = \"\"\"\n",
    "Command: Write an email from Bob, Customer Service Manager, to the customer \"John Doe\" \n",
    "who provided negative feedback on the service provided by our customer support \n",
    "engineer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b39943ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "body = json.dumps({\n",
    "    \"inputText\": prompt_data, \n",
    "    \"textGenerationConfig\":{\n",
    "        \"maxTokenCount\":4096,\n",
    "        \"stopSequences\":[],\n",
    "        \"temperature\":0,\n",
    "        \"topP\":0.9\n",
    "        }\n",
    "    }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37ce1173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:   \"Jane Doe\"\n",
      "Subject: Apology for Poor Service Experience\n",
      "\n",
      "Dear John Doe,\n",
      "\n",
      "I hope this email finds you well. I am writing to express my sincere apologies for the poor service experience you had when you contacted our customer support engineer Jane Doe.\n",
      "\n",
      "We strive to provide excellent service to all our customers, and it is disheartening to hear that we fell short of your expectations. We take feedback like yours very seriously, and we are committed to resolving the issue and ensuring that we provide better service in the future.\n",
      "\n",
      "If you would like to discuss this matter further, please do not hesitate to contact me directly. We value your opinion and want to make things right for you.\n",
      "\n",
      "Once again, I apologize for any inconvenience caused.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Bob Customer Service Manager\n"
     ]
    }
   ],
   "source": [
    "modelId = 'amazon.titan-tg1-large' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "outputText = response_body.get('results')[0].get('outputText')\n",
    "print('output: ', outputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3fbc9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\u001b[31m**Chunk 1**\u001b[0m\n",
      " \"Jane Doe\"\n",
      "Subject: Apology for Poor Service Experience\n",
      "\n",
      "Dear John Doe,\n",
      "\n",
      "I hope this email finds you well. I am writing to express my sincere apologies for the poor service experience you had when\n",
      "\n",
      "\t\t\u001b[31m**Chunk 2**\u001b[0m\n",
      " you contacted our customer support engineer Jane Doe.\n",
      "\n",
      "We strive to provide excellent service to all our customers, and it is disheartening to hear that we fell short of your expectations. We take feedback like yours very seriously, and we are committed to resolving the issue and ensuring that we provide better service in the future.\n",
      "\n",
      "If\n",
      "\n",
      "\t\t\u001b[31m**Chunk 3**\u001b[0m\n",
      " you would like to discuss this matter further, please do not hesitate to contact me directly. We value your opinion and want to make things right for you.\n",
      "\n",
      "Once again, I apologize for any inconvenience caused.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Bob Customer Service Manager\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['outputText']\n",
    "            output.append(text)\n",
    "            print(f'\\t\\t\\x1b[31m**Chunk {i}**\\x1b[0m\\n{text}\\n')\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59461889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\u001b[31m**COMPLETE OUTPUT**\u001b[0m\n",
      "\n",
      " \"Jane Doe\"\n",
      "Subject: Apology for Poor Service Experience\n",
      "\n",
      "Dear John Doe,\n",
      "\n",
      "I hope this email finds you well. I am writing to express my sincere apologies for the poor service experience you had when you contacted our customer support engineer Jane Doe.\n",
      "\n",
      "We strive to provide excellent service to all our customers, and it is disheartening to hear that we fell short of your expectations. We take feedback like yours very seriously, and we are committed to resolving the issue and ensuring that we provide better service in the future.\n",
      "\n",
      "If you would like to discuss this matter further, please do not hesitate to contact me directly. We value your opinion and want to make things right for you.\n",
      "\n",
      "Once again, I apologize for any inconvenience caused.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Bob Customer Service Manager\n"
     ]
    }
   ],
   "source": [
    "print('\\t\\t\\x1b[31m**COMPLETE OUTPUT**\\x1b[0m\\n')\n",
    "complete_output = ''.join(output)\n",
    "print(complete_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac335121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7987d18",
   "metadata": {},
   "source": [
    "## Bedrock streaming using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068fa96",
   "metadata": {},
   "source": [
    "[bedrock stream reference](https://github.com/langchain-ai/langchain/issues/9094)\n",
    "\n",
    "[Open AI stream reference](https://python.langchain.com/docs/modules/model_io/models/chat/streaming)\n",
    "\n",
    "[InvokeModelWithResponseStream](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_InvokeModelWithResponseStream.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35185a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a tortoise and a hare who were good friends. One day, the tortoise challenged the hare to a race. The hare accepted the challenge \n",
      "thinking that it will be an easy win. So, when the race started, the hare ran very fast leaving the tortoise way behind. He reached the finish line while the tortoise was still a long way behind. He looked back and saw that the tortoise was not far behind. So, he thought to himself that the tortoise will not be able to reach the finish line before he does. So, he took a nap.\n",
      "The tortoise and the hare had been friends for a long time. One day, they decided to have a race. The hare expected to win easily because the tortoise was moving \n",
      "so slowly. So he took a nap while the tortoise kept going. When the hare woke up, the tortoise was already at the finish line. To his dismay, the tortoise won the race while he was sleeping.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Generator\n",
    "\n",
    "def process_prompt_streaming(prompt) -> Generator[str, None, None]:\n",
    "    cont = True\n",
    "    prompt_text = prompt + '\\n'\n",
    "    while cont:\n",
    "        response_stream = bedrock_client.invoke_model_with_response_stream(\n",
    "            body=json.dumps({'inputText': prompt_text}),\n",
    "            modelId='amazon.titan-tg1-large',\n",
    "            accept='application/json',\n",
    "            contentType='application/json'\n",
    "        )\n",
    "        status_code = response_stream['ResponseMetadata']['HTTPStatusCode']\n",
    "        if status_code != 200:\n",
    "            raise ValueError(\n",
    "                f\"Error invoking Bedrock API: {status_code}\"\n",
    "            )\n",
    "        for response in response_stream['body']:\n",
    "            json_response = json.loads(response['chunk']['bytes'])\n",
    "            yield json_response['outputText']\n",
    "            if json_response['completionReason'] == 'FINISH':\n",
    "                cont = False\n",
    "                break\n",
    "\n",
    "for m in process_prompt_streaming('Command: Tell me a story about a tortoise and a hare.'):\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40172926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d47b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555fee81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb577d6b",
   "metadata": {},
   "source": [
    "[Implementing Locally-Hosted Llama2 Chat UI Using Streamlit](https://medium.com/@daydreamersjp/implementing-locally-hosted-llama2-chat-ui-using-streamlit-53b181651b4e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16c34b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3b9ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_llm()\n",
    "    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    return bedrock_client.invoke_model_with_response_stream(\n",
    "        body=json.dumps({'inputText': prompt_text}),\n",
    "        modelId='amazon.titan-tg1-large',\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1529ab47",
   "metadata": {},
   "source": [
    "# (2023-08-18) 현재 기준으로 아직 Bedrock stream을 Langchain을 제공할 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e40605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e3747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130fc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
